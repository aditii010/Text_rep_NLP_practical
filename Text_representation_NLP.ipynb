{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"this movie is very good\" ,\n",
        "    \"this movie is not very good\" ,\n",
        "    \"this movie is very bad\"\n",
        "\n",
        "]\n",
        "for d in documents :\n",
        "    print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xuNMXUCtVGt",
        "outputId": "a943b40b-a825-4abe-9aa2-8ea9adb7d7dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this movie is very good\n",
            "this movie is not very good\n",
            "this movie is very bad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vocabulary construction"
      ],
      "metadata": {
        "id": "pmUaT5cP0y1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(\" \".join(documents).split()))\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkSDwQJN001I",
        "outputId": "e2a76a4a-05ec-4d88-e7aa-f2a13ea26cfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bad', 'good', 'is', 'movie', 'not', 'this', 'very']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONE HOT ENCODING - filling 1 if the vocab exists, 0 if it doesnt , for each document in a 'V' dimensional matrix"
      ],
      "metadata": {
        "id": "9dwJszES1jqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def one_hot(word,vocab):\n",
        "  vector= np.zeros(len(vocab))\n",
        "  vector[vocab.index(word)]=1\n",
        "  return vector\n",
        "one_hot(\"good\",vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoZNSaTQ1uOo",
        "outputId": "6204e205-82b4-4c2b-d23a-d4f7303ea2b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BAG OF WORDS - DOCUMENT LEVEL REPRESENTATION\n",
        "counting word frequencies, disregarding grammar and word order."
      ],
      "metadata": {
        "id": "0AtAAZ6U2L8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow= CountVectorizer()\n",
        "bow_matrix = bow.fit_transform(documents)\n",
        "print(bow.get_feature_names_out())\n",
        "print(bow_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP3WRah12VNa",
        "outputId": "39ced046-4ced-4927-ee6a-920245759388"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bad' 'good' 'is' 'movie' 'not' 'this' 'very']\n",
            "[[0 1 1 1 0 1 1]\n",
            " [0 1 1 1 1 1 1]\n",
            " [1 0 1 1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF : where semantic relationships matter"
      ],
      "metadata": {
        "id": "8bGSjoan4Vcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf= TfidfVectorizer()\n",
        "tfidf_matrix= tfidf.fit_transform(documents)\n",
        "print(tfidf.get_feature_names_out())\n",
        "print(tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdDqXg0q4aCQ",
        "outputId": "9e27c83b-406d-48f9-eb20-d2e03405c5e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bad' 'good' 'is' 'movie' 'not' 'this' 'very']\n",
            "[[0.         0.54134281 0.42040099 0.42040099 0.         0.42040099\n",
            "  0.42040099]\n",
            " [0.         0.44102652 0.34249643 0.34249643 0.57989687 0.34249643\n",
            "  0.34249643]\n",
            " [0.64612892 0.         0.38161415 0.38161415 0.         0.38161415\n",
            "  0.38161415]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OZzA-VRc5Sg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "custom features"
      ],
      "metadata": {
        "id": "CIWx-Zzz5Tq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_words = {\"good\", \"very\"}\n",
        "negative_words = {\"bad\", \"not\"}\n",
        "def custom_features(text):\n",
        "    words=text.split()\n",
        "    pos = sum(1 for w in words if w in positive_words)\n",
        "    neg = sum(1 for w in words if w in negative_words)\n",
        "    length = len(words)\n",
        "    return [pos, neg, length]\n",
        "custom_feature_matrix = [custom_features(d) for d in documents]\n",
        "custom_feature_matrix\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DT2-XnD5UnQ",
        "outputId": "65e378e3-c1dd-47e4-9ff8-c312175b2310"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 0, 5], [2, 1, 6], [1, 1, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HYBRID FEATURES"
      ],
      "metadata": {
        "id": "eYUdiEjh6E-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "hybrid_features = np.hstack([\n",
        "    tfidf_matrix.toarray(),\n",
        "    np.array(custom_feature_matrix)\n",
        "])\n",
        "\n",
        "hybrid_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d0hJyga6GuR",
        "outputId": "0370804a-79e5-45b5-9bb6-73a714161275"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.54134281, 0.42040099, 0.42040099, 0.        ,\n",
              "        0.42040099, 0.42040099, 2.        , 0.        , 5.        ],\n",
              "       [0.        , 0.44102652, 0.34249643, 0.34249643, 0.57989687,\n",
              "        0.34249643, 0.34249643, 2.        , 1.        , 6.        ],\n",
              "       [0.64612892, 0.        , 0.38161415, 0.38161415, 0.        ,\n",
              "        0.38161415, 0.38161415, 1.        , 1.        , 5.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of N grams"
      ],
      "metadata": {
        "id": "amgNobnw7JUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mzOwq8wL8cni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngram = CountVectorizer(ngram_range=(1,2))\n",
        "ngram_matrix = ngram.fit_transform(documents)\n",
        "\n",
        "print(\"\\nBAG OF N-GRAMS - Vocabulary:\")\n",
        "print(ngram.get_feature_names_out())\n",
        "\n",
        "print(\"\\nBAG OF N-GRAMS - Matrix:\")\n",
        "print(ngram_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQQFd8737KYJ",
        "outputId": "32d7964a-48c5-4e6b-e1eb-7280668ba936"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BAG OF N-GRAMS - Vocabulary:\n",
            "['bad' 'good' 'is' 'is not' 'is very' 'movie' 'movie is' 'not' 'not very'\n",
            " 'this' 'this movie' 'very' 'very bad' 'very good']\n",
            "\n",
            "BAG OF N-GRAMS - Matrix:\n",
            "[[0 1 1 0 1 1 1 0 0 1 1 1 0 1]\n",
            " [0 1 1 1 0 1 1 1 1 1 1 1 0 1]\n",
            " [1 0 1 0 1 1 1 0 0 1 1 1 1 0]]\n"
          ]
        }
      ]
    }
  ]
}